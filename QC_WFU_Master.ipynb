{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1343ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e4143ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort</th>\n",
       "      <th>sires</th>\n",
       "      <th>dames</th>\n",
       "      <th>labanimalid</th>\n",
       "      <th>accessid</th>\n",
       "      <th>sex</th>\n",
       "      <th>rfid</th>\n",
       "      <th>dob</th>\n",
       "      <th>dow</th>\n",
       "      <th>shipmentdate</th>\n",
       "      <th>...</th>\n",
       "      <th>littersize</th>\n",
       "      <th>coatcolor</th>\n",
       "      <th>earpunch</th>\n",
       "      <th>rack</th>\n",
       "      <th>shipmentbox</th>\n",
       "      <th>housingbox</th>\n",
       "      <th>shipmentage</th>\n",
       "      <th>weanage</th>\n",
       "      <th>comments</th>\n",
       "      <th>resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C01</td>\n",
       "      <td>72539_1</td>\n",
       "      <td>72595_5</td>\n",
       "      <td>TJ008</td>\n",
       "      <td>73472_2</td>\n",
       "      <td>F</td>\n",
       "      <td>933000320045906</td>\n",
       "      <td>2018-09-24</td>\n",
       "      <td>2018-10-15</td>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>BROWNHOOD</td>\n",
       "      <td>RB</td>\n",
       "      <td>D-F4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9999</td>\n",
       "      <td>36.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Pregnant female/Impregnated</td>\n",
       "      <td>REMOVE_FROM_EXCLUSION_AND_REPLACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C01</td>\n",
       "      <td>73358_1</td>\n",
       "      <td>73360_1</td>\n",
       "      <td>TJ027</td>\n",
       "      <td>73477_2</td>\n",
       "      <td>F</td>\n",
       "      <td>933000320045890</td>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>2018-10-16</td>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>BROWNHOOD</td>\n",
       "      <td>LM</td>\n",
       "      <td>D-G8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>35.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C01</td>\n",
       "      <td>72539_1</td>\n",
       "      <td>72595_5</td>\n",
       "      <td>TJ003</td>\n",
       "      <td>73472_8</td>\n",
       "      <td>M</td>\n",
       "      <td>933000320045902</td>\n",
       "      <td>2018-09-24</td>\n",
       "      <td>2018-10-15</td>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>ALBINO</td>\n",
       "      <td>RT</td>\n",
       "      <td>D-F2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9999</td>\n",
       "      <td>36.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Pregnant female/Impregnated</td>\n",
       "      <td>REMOVE_FROM_EXCLUSION_AND_REPLACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C01</td>\n",
       "      <td>72794_1</td>\n",
       "      <td>72775_4</td>\n",
       "      <td>TJ020</td>\n",
       "      <td>73475_4</td>\n",
       "      <td>F</td>\n",
       "      <td>933000320045904</td>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>2018-10-16</td>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>RB</td>\n",
       "      <td>D-G2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9999</td>\n",
       "      <td>35.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Pregnant female/Impregnated</td>\n",
       "      <td>REMOVE_FROM_EXCLUSION_AND_REPLACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C01</td>\n",
       "      <td>72624_1</td>\n",
       "      <td>72596_4</td>\n",
       "      <td>TJ002</td>\n",
       "      <td>73471_5</td>\n",
       "      <td>F</td>\n",
       "      <td>933000320045908</td>\n",
       "      <td>2018-09-23</td>\n",
       "      <td>2018-10-15</td>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>LT</td>\n",
       "      <td>D-F2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9999</td>\n",
       "      <td>37.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Pregnant female/Impregnated</td>\n",
       "      <td>REMOVE_FROM_EXCLUSION_AND_REPLACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>C07</td>\n",
       "      <td>933000320048190</td>\n",
       "      <td>933000320187377</td>\n",
       "      <td>NA</td>\n",
       "      <td>None</td>\n",
       "      <td>F</td>\n",
       "      <td>933000320125436</td>\n",
       "      <td>2020-08-09</td>\n",
       "      <td>2020-09-04</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>C07</td>\n",
       "      <td>933000320187153</td>\n",
       "      <td>933000320187383</td>\n",
       "      <td>NA</td>\n",
       "      <td>None</td>\n",
       "      <td>F</td>\n",
       "      <td>933000320125437</td>\n",
       "      <td>2020-08-09</td>\n",
       "      <td>2020-09-04</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>BROWNHOOD</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>C07</td>\n",
       "      <td>933000320187217</td>\n",
       "      <td>933000320048245</td>\n",
       "      <td>NA</td>\n",
       "      <td>None</td>\n",
       "      <td>F</td>\n",
       "      <td>933000320125440</td>\n",
       "      <td>2020-08-09</td>\n",
       "      <td>2020-09-04</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>C07</td>\n",
       "      <td>933000320187249</td>\n",
       "      <td>933000320048234</td>\n",
       "      <td>NA</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>933000320125443</td>\n",
       "      <td>2020-08-08</td>\n",
       "      <td>2020-09-04</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>BLACKHOOD</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>C07</td>\n",
       "      <td>933000320048237</td>\n",
       "      <td>933000320048247</td>\n",
       "      <td>NA</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>933000320125448</td>\n",
       "      <td>2020-08-08</td>\n",
       "      <td>2020-09-04</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>BROWNHOOD</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>901 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cohort            sires            dames labanimalid accessid sex  \\\n",
       "0      C01          72539_1          72595_5       TJ008  73472_2   F   \n",
       "1      C01          73358_1          73360_1       TJ027  73477_2   F   \n",
       "2      C01          72539_1          72595_5       TJ003  73472_8   M   \n",
       "3      C01          72794_1          72775_4       TJ020  73475_4   F   \n",
       "4      C01          72624_1          72596_4       TJ002  73471_5   F   \n",
       "..     ...              ...              ...         ...      ...  ..   \n",
       "896    C07  933000320048190  933000320187377          NA     None   F   \n",
       "897    C07  933000320187153  933000320187383          NA     None   F   \n",
       "898    C07  933000320187217  933000320048245          NA     None   F   \n",
       "899    C07  933000320187249  933000320048234          NA     None   M   \n",
       "900    C07  933000320048237  933000320048247          NA     None   M   \n",
       "\n",
       "                rfid         dob         dow shipmentdate  ...  littersize  \\\n",
       "0    933000320045906  2018-09-24  2018-10-15   2018-10-30  ...         8.0   \n",
       "1    933000320045890  2018-09-25  2018-10-16   2018-10-30  ...        11.0   \n",
       "2    933000320045902  2018-09-24  2018-10-15   2018-10-30  ...         8.0   \n",
       "3    933000320045904  2018-09-25  2018-10-16   2018-10-30  ...        11.0   \n",
       "4    933000320045908  2018-09-23  2018-10-15   2018-10-30  ...         7.0   \n",
       "..               ...         ...         ...          ...  ...         ...   \n",
       "896  933000320125436  2020-08-09  2020-09-04         None  ...         9.0   \n",
       "897  933000320125437  2020-08-09  2020-09-04         None  ...        11.0   \n",
       "898  933000320125440  2020-08-09  2020-09-04         None  ...        11.0   \n",
       "899  933000320125443  2020-08-08  2020-09-04         None  ...        10.0   \n",
       "900  933000320125448  2020-08-08  2020-09-04         None  ...        11.0   \n",
       "\n",
       "     coatcolor earpunch  rack shipmentbox  housingbox shipmentage  weanage  \\\n",
       "0    BROWNHOOD       RB  D-F4         2.0        9999        36.0     21.0   \n",
       "1    BROWNHOOD       LM  D-G8         4.0          32        35.0     21.0   \n",
       "2       ALBINO       RT  D-F2         2.0        9999        36.0     21.0   \n",
       "3        BROWN       RB  D-G2         2.0        9999        35.0     21.0   \n",
       "4        BLACK       LT  D-F2         2.0        9999        37.0     22.0   \n",
       "..         ...      ...   ...         ...         ...         ...      ...   \n",
       "896      BLACK     None  None         NaN        None         NaN     26.0   \n",
       "897  BROWNHOOD     None  None         NaN        None         NaN     26.0   \n",
       "898      BROWN     None  None         NaN        None         NaN     26.0   \n",
       "899  BLACKHOOD     None  None         NaN        None         NaN     27.0   \n",
       "900  BROWNHOOD     None  None         NaN        None         NaN     27.0   \n",
       "\n",
       "                        comments                         resolution  \n",
       "0    Pregnant female/Impregnated  REMOVE_FROM_EXCLUSION_AND_REPLACE  \n",
       "1                             NA                                 NA  \n",
       "2    Pregnant female/Impregnated  REMOVE_FROM_EXCLUSION_AND_REPLACE  \n",
       "3    Pregnant female/Impregnated  REMOVE_FROM_EXCLUSION_AND_REPLACE  \n",
       "4    Pregnant female/Impregnated  REMOVE_FROM_EXCLUSION_AND_REPLACE  \n",
       "..                           ...                                ...  \n",
       "896                           NA                                 NA  \n",
       "897                           NA                                 NA  \n",
       "898                           NA                                 NA  \n",
       "899                           NA                                 NA  \n",
       "900                           NA                                 NA  \n",
       "\n",
       "[901 rows x 21 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def runQuery(query):\n",
    "    #insert database access\n",
    "   \n",
    "    cursor = connection.cursor()\n",
    "    if \"SELECT\" in query:\n",
    "        table = pd.read_sql(query, con = connection)\n",
    "    elif \"UPDATE\" in query:\n",
    "        cursor.execute(query)\n",
    "        print(query)\n",
    "        connection.commit()\n",
    "    elif \"DELETE\" in query:\n",
    "        cursor.execute(query)\n",
    "        print(query)\n",
    "        connection.commit()\n",
    "    else:\n",
    "        return None\n",
    "    if connection:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        if \"SELECT\" in query:\n",
    "            return table\n",
    "        else:\n",
    "            return\n",
    "\n",
    "\n",
    "runQuery(\"SELECT * FROM u01_suzanne_mitchell.wfu_master\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "25b87acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C01 sires total 100 dups 34\n",
      "C01 dames total 100 dups 34\n",
      "C02 sires total 110 dups 44\n",
      "C02 dames total 110 dups 44\n",
      "C03 sires total 100 dups 40\n",
      "C03 dames total 100 dups 40\n",
      "C04 sires total 100 dups 48\n",
      "C04 dames total 100 dups 48\n",
      "C05 sires total 100 dups 51\n",
      "C05 dames total 100 dups 51\n",
      "C06 sires total 100 dups 50\n",
      "C06 dames total 100 dups 50\n",
      "C07 sires total 291 dups 99\n",
      "C07 dames total 291 dups 99\n",
      "listed as dame and sire ['nan']\n",
      "parent pairs 396\n",
      "parent pair across multiple cohorts found ['C01', 'C02']\n",
      "parent pair across multiple cohorts found ['C01', 'C02']\n",
      "parent pair across multiple cohorts found ['C01', 'C02']\n",
      "parent pair across multiple cohorts found ['C01', 'C02']\n",
      "parent pair across multiple cohorts found ['C01', 'C02']\n",
      "parent pair across multiple cohorts found ['C02', 'C03']\n",
      "parent pair across multiple cohorts found ['C02', 'C03']\n",
      "parent pair across multiple cohorts found ['C04', 'C06']\n",
      "parent pair across multiple cohorts found ['C04', 'C06']\n",
      "parent pair across multiple cohorts found ['C04', 'C06']\n",
      "parent pair across multiple cohorts found ['C04', 'C06']\n",
      "parent pair across multiple cohorts found ['C05', 'C06']\n",
      "parent pair across multiple cohorts found ['C05', 'C06']\n",
      "parent pair across multiple cohorts found ['C05', 'C06']\n",
      "parent pair across multiple cohorts found ['C05', 'C06']\n",
      "parent pair across multiple cohorts found ['C05', 'C06']\n",
      "parent pair across multiple cohorts found ['C05', 'C06']\n",
      "parent pair across multiple cohorts found ['C05', 'C06']\n",
      "parent pair across multiple cohorts found ['C05', 'C06']\n",
      "parent pair across multiple cohorts found ['C05', 'C06']\n",
      "[ 8.  7. 13. 15. 11.  9.  6.  5. 10. 14.  3. 12.  4.  2. 16.  1.]\n",
      "[ 8.  7. 13. 15. 11.  9.  6.  5. 10. 14.  3. 12.  4.  2. 16.  1.]\n",
      "[ 4.  6.  8. 11.  7. 12.  9.  3.  5.  2. 10.  1. -1. 13. 15. 14.  0. -2.\n",
      " -4.]\n",
      "               sires            dames  siblings         dob  litter_size  \\\n",
      "32           72782_3          72778_4         4  2018-10-02          3.0   \n",
      "290          74167_1          74198_2         2  2020-02-06          2.0   \n",
      "305  933000320187131  933000320048250         1  2020-08-26          1.0   \n",
      "309  933000320187363  933000320187175         3  2020-07-26          3.0   \n",
      "314  933000320187344  933000320187245         4  2020-07-24          4.0   \n",
      "322  933000320186992  933000320186969         3  2020-07-27          3.0   \n",
      "329  933000320187165  933000320187209         3  2020-08-15          1.0   \n",
      "339  933000320187430  933000320187365         3  2020-07-31          3.0   \n",
      "381              nan              nan         6  2020-09-30          2.0   \n",
      "\n",
      "     removed_litter  \n",
      "32             -1.0  \n",
      "290             0.0  \n",
      "305             0.0  \n",
      "309             0.0  \n",
      "314             0.0  \n",
      "322             0.0  \n",
      "329            -2.0  \n",
      "339             0.0  \n",
      "381            -4.0  \n"
     ]
    }
   ],
   "source": [
    "def qc_pedigree(data):\n",
    "    data = data.sort_values([\"cohort\", \"labanimalid\"])\n",
    "    # Printing number of mothers and fathers per cohort\n",
    "    for cohort in np.unique(data[\"cohort\"]):\n",
    "        subset = data[data[\"cohort\"] == cohort]\n",
    "        sires = list(subset[\"sires\"])\n",
    "        dames = list(subset[\"dames\"])\n",
    "        print(cohort, \"sires\", \"total\", len(sires), \"dups\", len(set(sires)))\n",
    "        print(cohort, \"dames\", \"total\", len(dames), \"dups\", len(set(dames)))\n",
    "    # Printing animals listed as mother and father\n",
    "    sires = list(data[\"sires\"])\n",
    "    dames = list(data[\"dames\"])\n",
    "    overlap = set(dames).intersection(set(sires))\n",
    "    #print(\"sires\", len(set(sires)), \"dames\", len(set(dames)), \"overlap\", len(overlap))\n",
    "    print(\"listed as dame and sire\", list(overlap))\n",
    "    # Checking sibling numbers\n",
    "    parents_dict = {}\n",
    "    dob = []\n",
    "    litter = []\n",
    "    parents_df = pd.DataFrame()\n",
    "    for index, row in data.iterrows():\n",
    "        parents = (row[\"sires\"], row[\"dames\"])\n",
    "        \n",
    "        if parents in parents_dict.keys():\n",
    "            parents_dict[parents].append(row[\"rfid\"])\n",
    "        else:\n",
    "            dob.append(row['dob'])\n",
    "            litter.append(row['littersize'])\n",
    "            parents_dict[parents] = [row[\"rfid\"]]\n",
    "            parents_df = parents_df.append({'sires':row[\"sires\"],'dames':row[\"dames\"]},ignore_index = True)\n",
    "    print(\"parent pairs\", len(parents_dict.keys()))\n",
    "    siblings = []\n",
    "    for parents in parents_dict.keys():\n",
    "        #print(parents, len(parents_dict[parents]))#, parents_dict[parents])\n",
    "        siblings.append(len(parents_dict[parents]))\n",
    "        cohorts = []\n",
    "        for rfid in parents_dict[parents]:\n",
    "            subset = data[data[\"rfid\"] == rfid]\n",
    "            subset.index = range(subset.shape[0])\n",
    "            i_cohort = list(subset.columns).index(\"cohort\")\n",
    "            cohorts.append(subset.iloc[0, i_cohort])\n",
    "        cohorts = list(np.unique(cohorts))\n",
    "        if len(cohorts) != 1:\n",
    "            print(\"parent pair across multiple cohorts found\", cohorts)\n",
    "    parents_df['siblings'] = siblings\n",
    "    parents_df['dob'] = dob\n",
    "    parents_df['litter_size'] = litter\n",
    "    parents_df['removed_litter'] = parents_df['litter_size'] - parents_df['siblings']\n",
    "\n",
    "    #print(parents_df)\n",
    "    print(parents_df.litter_size.unique())\n",
    "    print(data.littersize.unique())\n",
    "    print(parents_df.removed_litter.unique())\n",
    "    df_litter_error = parents_df[(parents_df['removed_litter'] <= 0)]\n",
    "    print(df_litter_error)\n",
    "    return\n",
    "qc_pedigree(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a52693a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C01', 'C04', 'C05', 'C02', 'C03', 'C06', 'C07'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split data based on cohorts\n",
    "#each cohort has their own df named after their cohort. Ex. C07\n",
    "cohorts = data.cohort.unique()\n",
    "for i in cohorts:\n",
    "    a = data[data.cohort == i]\n",
    "    globals()[f\"{i}\"] = a\n",
    "cohorts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d6d291d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C01': datetime.timedelta(days=11),\n",
       " 'C04': datetime.timedelta(days=13),\n",
       " 'C05': datetime.timedelta(days=13),\n",
       " 'C02': datetime.timedelta(days=13),\n",
       " 'C03': datetime.timedelta(days=13),\n",
       " 'C06': datetime.timedelta(days=19),\n",
       " 'C07': datetime.timedelta(days=71)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check that the dob for each cohort is within a certain range\n",
    "#right now just outputs the cohort with the day span\n",
    "dob_range = {}\n",
    "for i in cohorts:\n",
    "    globals()[f\"dates_{i}\"] = globals()[f\"{i}\"].dob.unique()\n",
    "    oldest = min(globals()[f\"dates_{i}\"])\n",
    "    youngest = max(globals()[f\"dates_{i}\"])\n",
    "    difference = youngest - oldest\n",
    "    dob_range[i] = difference\n",
    "dob_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fde6d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nan']\n"
     ]
    }
   ],
   "source": [
    "#Check if there are any matching ids between sires and dames\n",
    "unique_sires = data.sires.unique()\n",
    "unique_dames = data.dames.unique()\n",
    "print([x for x in unique_sires if x in unique_dames])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0fbf690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BROWNHOOD', 'ALBINO', 'BROWN', 'BLACK', 'BLACKHOOD'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check namiing of coat colors\n",
    "unique_coats = data.coatcolor.unique()\n",
    "unique_coats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e9c429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10124c74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
